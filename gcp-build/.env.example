# ── Model Build (gcp-build/ scripts) ─────────────────────
# Required by: ./gcp-build/cloud-build-medgemma.sh
# See: Specs/experiments/CLOUD-BUILD-SPEC.md

# HuggingFace access token (read-only, for gated model download)
# Get from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_...

# Ollama registry SSH key file (for pushing built models)
# Generate: ssh-keygen -t ed25519 -f ~/.ssh/ollama
# Register public key at: https://ollama.com/settings/keys
# OLLAMA_KEY_FILE=~/.ssh/ollama

# Ollama registry namespace (your Ollama username)
# OLLAMA_REGISTRY_NS=myuser

# Google Cloud Storage bucket for build artifacts
# GCS_BUCKET=my-model-build

# GCE instance configuration (optional — defaults work for 4B models)
# Scale up for larger models (e.g., 70B needs more RAM/disk)
# GCE_MACHINE_TYPE=e2-standard-8    # 8 vCPU, 32 GB (default)
# GCE_DISK_SIZE=100GB               # Boot disk size (default)
# GCE_DISK_TYPE=pd-ssd              # Disk type (default)
# GCE_ZONE=us-central1-a            # GCE zone (default)
# GCE_MAX_RUN=3600s                 # Max instance lifetime (default: 1h)